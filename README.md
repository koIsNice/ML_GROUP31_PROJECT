### Result
For the final project, we join a competition in Kaggle [(Link)](https://www.kaggle.com/competitions/um-game-playing-strength-of-mcts-variants) and we ranked 282/1610, where the score is 0.43377 in the private leaderboard (RMSE metric).

### Model & Dataset & preprocess.py
In this project, we use the model Catboost with the preprocessed dataset.
The dataset can be obtained by unzip the dataset.zip. We can get the preprocessed dataset by execute the preprocess.py with the unzipped dataset.

### main.py
Once we obtain the preprocessed data, we can execute the blocks in main.ipynb block by block to train the model.

### trained model
We also upload a zipped catboost model in the directory 'models'. We can use it by unzip the cat_adv.zip .